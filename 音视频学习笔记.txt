采样率：定义了每秒从连续信号中提取并组成离散信号的采样个数，单位是Hz，是录制设备录制时用到的参数
码率：也叫比特率，同等分辨率的视频传输码率越大越清晰，视频也越大，耗费网络越多，单位是kbps即千位每秒。
码率和采样率有正相关。
宽带的单位是位每秒，1M宽带表示1024K位每秒，换算成字节是1024/8 = 128 KB/s
由于宽带和码率的单位一样，所以码率*帧速率=视频每秒需要的宽带

Web主流的视频直播方案有hls、rtsp、MPEG-DASH和rtpm
hls协议是以http协议为基础的，有一个视频文件播放列表文件m3u8后缀和若干ts文件，视频编码格式是h264，音频编码格式为MP3、AAC或者AC-3，延迟比较大10s以上
可以使用hls.js实现，https://github.com/video-dev/hls.js
也可以借助videojs库及它的插件videojs-contrib-hls实现
<source src="http://10.10.5.119/live/livestream.m3u8" type='application/x-mpegURL'>
对于直播流，m3u8文件会在播放过程中定期更新（浏览器自动完成），参考：https://blog.csdn.net/qq_39969226/article/details/105634280

rtsp，实时流传输协议，是TCP/IP协议体系中的一个应用层协议，浏览器不支持播放，需要安装插件

MPEG-DASH需要先下载一个媒体演示描述 (MPD) 文件，xml格式，然后根据描述信息分段下载视频文件，实现需要借助dash.js库或者手动实现https://blog.csdn.net/haima1998/article/details/38865023

rtpm是一种实时传输协议，一般传输的是 flv，f4v 格式流，延迟更低，需要在flash播放器上播放的，H5的video播放器是不能播放的。

可以借助videojs库或者其他flash库实现播放，V5.20.4是最后一个版本支持，V6.x.x以后的版本核心库不支持了，因为flash正在被淘汰，chrome88开始不支持flash
<source src="rtmp://live.hkstv.hk.lxdns.com/live/hks" type="rtmp/flv">
也可以借助flv.js库播放flv格式的流，原理是内部转化格式fmp4格式，再通过 Media Source Extension（MSE） 喂给浏览器的 video 标签。

HTTP-FLV协议是rtpm协议的升级，采用http长连接，不用分片，延时低，结合了hls和rtpm的特点。

hls.js和dash.js的实现原理也都是通过MSE实现的

多路出流/多轨道问题：
默认情况下可以添加一个流，包含一个音频轨道，一个视频轨道，或者其中一个
如果要添加一个新流，则必须由offer端先添加，否则answer添加的新流offer端无法获取
如果要添加默认的音频/视频轨道之前的新轨道，同样需要offer端先添加，否则answer端添加的新轨道offer端无法获取
Offer端可以任意添加新流或者新轨道，answer端都可以获取

使用HTMLMediaElement.captureStream()可以捕获一个正在播放的视频的流对象，因此可以利用这个特性在webrtc中给远端共享预先录制的视频，视频资源跨域需要添加跨域资源共享属性crossorigin="anonymous"

浏览器如何播放H265编码的视频？
目前浏览器对H265对支持还很少，如果要播放就需要libde265.js，libde265.js是一个通过JS来解码H.265视频的库，它通过将 视频的 frame data 转化为 rgba 像素，然后绘制到 Canvas 上。
demo地址：https://github.com/strukturag/libde265.js/blob/master/demo/libde265.html