谷歌TenosrFlow开发者峰会2018上，发布了面向JavaScript开发者的全新机器学习框架 TensorFlow.js

深度学习大致流程

输入数据（图像，目标）和预期的结果
通过神经网络进行大量训练
训练完成就可以识别对应的图像得到预期的结果

卷积神经网络（简称CNN）在图像分类、图像分割、目标检测等领域获得广泛应用。
常用的轻量化网络结构：SqueezeNet、MobileNet、ShuffleNet、Xception
神经网络都是由多层网络组成，如卷积层、池化层、全连接层，
每一层都要若干个节点，称为神经元，每个神经元都是一个带有权重和偏置的函数，它接收一个或多个输入，这些输入乘以被称为“权重”的值并相加，然后，这个值被传递给一个非线性函数，称为激活函数，以生成神经元的输出。
卷积神经网络的神经元不都是全连接的，这区别与一般神经网络。

所谓卷积就是对图像进行卷积计算，简单理解就是矩阵乘法运算，每个卷积层都有若干个卷积核，也叫滤波器，卷积核就是图像处理时，给定输入图像，输入图像中一个小区域中像素加权平均后成为输出图像中的每个对应像素，其中权值由一个函数定义，这个函数称为卷积核，每个卷积核对应一种图像特征。

神经元和卷积核的关系
一个卷积核是由多个类似于一般神经网络中的神经元组成的，特征图中的矩阵元素的个数，即相当相应卷积核中的神经元个数，例如这里等价的每个卷积核神经元个数是4*4=16个，即每个卷积核就是由16个神经元组成，然后第一层总共有三个卷积核，所以第一层总共有16*3=48个神经元。
参考：https://blog.csdn.net/whr_ws/article/details/82822680

循环（递归）神经网络（简称RNN）在文本领域广泛应用。

一篇文章让你了解大模型项目的整个研发流程
https://zhuanlan.zhihu.com/p/654733518

如何利用开源大模型（模型基座）训练一个自己的大模型？
SFT（Supervised Finetuning，有监督微调）一种训练方法，当然还有其他方法
1. 模型基座预训练（开源大模型已完成）
2. 词表扩充
开源大模型可能会存在两个问题：
  1 语言不匹配，如[Llama]、[mpt]、[falcon]
  2 专业知识不足
因此需要词表扩充，也就是将一些常见的汉字 token 手动添加到原来的 tokenizer 中
3. 预训练
在扩充完 tokenizer 后，我们就可以开始正式进行模型的预训练步骤了。
预训练的思路很简单，就是输入一堆文本，让模型做 Next Token Prediction 的任务。
预训练过程中所用到的方法：数据源采样、数据预处理、模型结构。
4. 指令微调
  1 Self Instruction 自定义数据
由于预训练任务的本质在于「续写」，而「续写」的方式并一定能够很好的回答用户的问题。
既然模型知道这些知识，只是不符合我们人类的对话习惯，那么我们只要再去教会模型「如何对话」就好了。
既然我们需要去「教会模型说人话」，那么我们就需要去精心编写各式各样人们在对话中可能询问的问题，以及问题的答案。
如果这件事从头开始做自然很难（OpenAI 确实厉害），但今天我们已经有了 ChatGPT 了，Self Instruction 的思路，即通过 ChatGPT 的输入输出来蒸馏自己的模型。
通俗来讲，就是人为的先给一些「训练数据样例」让ChatGPT看，紧接着利用ChatGPT的续写功能，让其不断地举一反三出新的训练数据集。
  2 开源数据集整理
整理开源数据集成问题和答案，然后给大模型进行训练。
5.训练奖励模型Reward Model
奖励模型开源对一个问题的回答进行好坏打分
6.强化学习（Reinforcement Learning，PPO）
利用奖励模型进化微调后的模型，使模型有了区分好坏答案的能力

【LLM】从零开始训练大模型
https://zhuanlan.zhihu.com/p/636270877

